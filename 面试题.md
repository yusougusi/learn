# 面试题

# Hive

#### 0.MySQL的登陆和登出

1.明文登录：

```
mysql -u账号 -p密码
```

2.暗文登录：

```
mysql -u账号 -p  敲回车
输入密码
```

3.指定服务器登录：

```
mysql --host ip地址  --user=账号 --password=密码
```

登出：exit或quit



#### 0.1请简述你对拉链表的理解（他是啥，作用，怎么实现？）

#### 1.请简述你常用的Linux命令

ssh命令：用于本地和远程服务器之间建立安全连接，用于执行各种远程命令操作

ls命令：列出目录的内容

cd命令：切换目录

mkdir命令：创建一个新目录

touch命令：创建一个空文件

mv命令：移动或重命名文件或目录

tar命令：压缩，解压缩



#### 2.desc的作用

查看表的结构信息，排序时倒序



#### 3.大数据的特点

5v（大多值快信）

大：大数据数据量庞大

多：数据类型多

值：大数据整体有重要价值

快：大数据处理速度块

信：数据的来源和品质可信度高



#### 4.delete from 和 truncate table 之间的区别是什么?

它们的共同点时都会清空表数据

但是，

delete from：删除表数据，但主键ID不会重置

truncate table：删除表数据，会重置主键，相当于直接删除整个表，在重新造一个一模一样的表



#### 5.count(1), count(列), count(*)的区别是什么?

count(1)、count（列）、count（*）的作用都一样，在处理null值有所不同

count（1）count（*）在统计时不会忽略null值，效率上几乎无差别

count（列）只统计该列的非NUll值。因为有判断所以效率较其他两个较低

所以效率上count（1）>count(*)>count(列)



#### 6.聚合函数有哪些？

sum（）：求和

max（）：最大值

min（）：最小值

avg（）：平均值

count（）：计数



#### 7.having和where的区别

having：组后筛选，后面可以跟聚合函数

where：组前筛选，后面不能跟聚合函数



#### 8.ETL和ELT的区别

ETL是指抽取、转换、装载，他是先处理，后存储，属于老的数仓方式，容易丢数据

ELT时新的数仓方式，抽取后直接存储到数仓中，让后在数仓中对数据做处理



#### 9.请简述SSH免密登录的原理

SSH：非对称加密协议

简化：公钥加密私钥解密

详细：

1.客服端向服务端发起ssh请求

2.服务端收到请求发送公钥给客户端

3.客户端输入用户名和密码，通过公钥加密回传给服务端

4.服务端通过私钥解密得到用户名和密码跟本地进行比对，验证成功允许登录否则再次验证



#### 10.请简述数据分析的流程是什么？

​	5w2h法：

- **What**（什么）：我们需要解决什么问题？
- **Why**（为什么）：我们为什么要解决这个问题？
- **When**（何时）：我们什么时候应该解决这个问题？
- **Where**（哪里）：我们应该在哪里解决这个问题？
- **Who**（谁）：我们应该指定谁来解决这个问题？
- **How**（如何）：我们应该如何解决这个问题？
- **How many**（多少）：我们需要多少资源来解决这个问题？
- **How much**（多少）：解决这个问题需要多少成本？



1.明确数据分析的目的和思路

​	5w2h法

2.数据采集

3.数据预处理

4.数据分析

5.数据展示

6.撰写报告



#### 11.zookeeper是什么？

zookeeper是一个分布式协调服务，帮助我们管理大数据集群

zookeeper还是一个小型文件存储系统，以znode节方式存储文件，每个znode不超过1MB

#### 12.zookeeper中的角色

##### leader：主节点

1.管理整个zk集群，保证数据全局一致性

2.负责处理数据事务（增删改查）请求

3.负责转发非数据事务（查）给从节点



##### follower：从节点

1.实时从主节点中实时拉取数据，保证数据全局一致性

2.负责除了非数据事务（查）请求

3.负责转发数据事务（增删改查）给主节点

4.有投票权



##### observer：观察者

除了没有选举权其他和follower一样，只有数据达到一定量级才会用到比如一些大公司



#### 13.zookeeper的四种节点类型

1.永久节点

2.临时节点

3.永久有序节点

4.临时有序节点



#### 14.ZK的选举机制

1.每个ZK节点启动时都会投票给MYID值大的机器

2.没选出主节点前，每开启一台机器就会选举一次

3.采用过半原则，得到票数超过集群的一半，即为主节点，其他为从节点

注：新集群参考myid值，旧集群优先参考机器节点数，如果节点数一样在参考myid值

#### 15.ZK是如何完成主备切换的

watch监听机制+临时节点

1.当集群启动时，所有节点都会抢占式的在ZK中创建一个临时节点，谁创建出来谁就是active，否则为standby

2.所有standby状态的节点会实时监听zk集群下的那个临时节点信息；即为注册监听

3.当绘画断开时，此时临时节点消失；即为事件触发

4.此时其他节点就会从standby状态切换到active状态；即获取结果



##### 监听机制：

1.先注册监听事件

2.当事件触发时就会获取结果

3.watch监听机制是一次性的

4.流程为：注册监听 ->事件触发->获取结果



#### 16.什么是hadoop

hadoop是一个分布式系统基础架构，主要解决了海量数据的存储和海量数据分析计算问题

HDFS：分布式文件系统  ->解决了海量数据存储

Yarn：集群资源管理和任务调度

mapreduce：分布式计算框架  ->解决了海量数据计算问题

我们使用的是商业版CDH，端口号是7180



#### 17.HDFS和Yarn个角色的作用

##### HDFS：

namenode（主节点）：1.负责管理整个HDFS集群

​					  				     2.负责存储和管理元数据



secondary namenode（辅助节点）：1.辅助namenode管理元数据



datanode（从节点）：1.负责存储具体数据

​										 2.负责数据的读写操作



##### Yarn:

resource manager(主节点)：1.负责资源分配

​												   2.负责计算任务的接收



appmaster(进程)：1.负责任务的分配

​                                 2.他是运行在nodemanager上的



nodemanager（从节点）：1.负责具体任务的执行



此时已经没有mapreduce了，它变成了一个组件，运行在Yarn上，通过代码实现操作HDFS的文件



#### 18.namenode是如何管理datanode的？

心跳机制、副本机制、负载均衡



##### 心跳机制：

1.datanode会隔一段时间（3秒）想namenode大宋心跳包，告知namenode它正常工作

2.如果超过一定时间（3秒），namenode没有收到心跳包，那么就会判定该datanode为假死状态

​	如果超过630秒（10次心跳3*10，2次最大间隔2 *5分钟）还没有收到心跳包，就知道datanode宕机了

3.namenode会将该datanode上存储的block块转移到其他datanode上

4.因为namenode是管理元数据的，datanode是存储数据的，所以datanode会定时（6个小时）向namenode汇报自己完整的信息。



##### 副本机制：

1.为了提高数据的容错率，所以HDFS的副本机制会默认副本为3，好处是：副本越高容错率越高，坏处是：磁盘的利用率降低了

2.实际开发中副本数为2~5

3.如果block块的副本数超过了默认副本数，那么namenode会自动删除多于副本

4.如果block块的副本数小于默认副本数，那么namenode会自动添加副本达到默认副本数

5.如果无法新增副本，且没有达到默认副本数，就会强制进入到安全模式，安全模式只能读不能写

​	解决方法是增加节点或手动删除有问题的block块，最后退出安全模式



##### 负载均衡：

namenode会尽量保证所有datanode存储的blck块以及资源利用率保持均衡



#### 19.我们知道HDFS的默认副本数是3，请问这3个副本是如何存储的？

根据副本数，网络拓扑图，负载均衡原理

将第1个副本存储到当前机架的某个服务器上

将第2个副本存储到当前机架不同机器的某个服务器上

将第3个副本存储到第2个副本所在不同机器的就近某个服务器上

如果不满上述条件，就随机存储。



#### 20.HDFS的的写入流程

1.客户端请求namenode上传数据

2.namenode接到请求后会判断该客户端有没有（写）权限，如果没有权限则报错，有权限会判断该文件的父目录是否存在，不存在就报	错，存在就告知客户端可以上传

3.数据按照指定block块大小切块操作

4.请求namenode第一个block块的上传位置，即到哪个datanode

5.namenode会获取存储的block块的datanode队列

6.根据namenode返回的datanode队列和依次和datanode建立连接，形成传输管道

7.采用数据包（最大64kb）的方式，在传输管道依次发送，并建立反向应答机制

8.然后就是正常的IO流动作，直至传送完毕



#### 21.HDFS的读取流程

1.客户端请求读取数据

2.namenode收到请求后，会判断客户端是否有（读）权限，没有就报错，有就判断文件是否存在，没有接报错，有就返回给客户端该文	件的block块地址

3.客户端根据这些地址找到datanode队列，并从中读取block块的数据

4.上述block块数据读取完毕后，会继续询问namenode剩余的或全部的block信息，然后并行读取，直至所有block块读取完毕

5.然后按照block块的信息，将这些block块组合成一个完整文件



#### 22.namenode是怎么管理元数据的

1.当客户端对HDFS进行增删改查等操作时，这些元数据会被记录下来并存储到内存中，叫内存元数据

2.内存元数据会实时写入到磁盘的编辑日志文件

3.当编辑日志文件达到一定阈值时，1小时或100w次会和镜像文件合并，生成新的镜像文件存储到磁盘中



#### 23.secondarynamenode是怎么辅助namenode管理元数据的？

1.secondarynamenode会实时监听namenode的编辑日志文件状态，只要达到一定阈值（1小时或100w次）就会提醒namenode形成新	的编辑日志文件，旧的就会禁用

2.然后从namenode中拉取编辑日志文件和镜像文件到secondarynamenode中合成新的镜像文件，

3.将上述新镜像文件推送给namenode。



#### 23.请简述MR的执行流程

Map：

1.读取HDDS中的文件。每一行解析成一个键值对，每一个键值对都调用一次map函数

2.覆盖map函数，接受键值对进行处理，转换成新的键值对输出，比如k1，v1，转换成k2、v2

3.对于输出的k2、v2进行分区，默认为一个分区

4.对不同分区的数据按照Key进行排序分组，，就是将相同key的放到一个集合中

5.对分组后的数据进行规约、目的是为了减少reduce端的数据量



Reduce：

1.对map输出的数据，按照不同分区，分到不同reduce节点上

2.对数据进行合并、排序，覆盖reduce函数，将输出的K2、V2处理传换成K3、V3

3.最后将reduce输出的数据写入到HDFS上



#### 24.1Yarn的架构

ResourceManager（主节点）：管理和调度集群资源

NodeManager（从节点）：管理本机资源和任务执行

AppMaster（进程）：程序级别，运行在NodeManager上的。用来监控和管理具体任务的执行，以及向ResourceManager申请资源

container（资源容器）：用来存储任务所需的资源



#### 24.2请简述yarn的三大调度策略

1.先进先出调度器：类似单线程，每个人物独占所有资源

2.容量调度器，类似于多线程，可以手动设置借调资源比例

3.公平调度器：类似多线程，CDH默认使用，类似于多线程，共享集群，动态分配资源



#### 25.请简述Yarn执行计算任务的流程

1.客户端向ResoureManager提交程序

2.resourcemanger启动一个conteiner用来运行appmaster

3.启动中的appmaster向resourmanager注册自己，启动成功后华人RM保持心跳

4.appmaster向RM发送请求，申请相应数目的container

5.申请成功后，由appmaster对container进行初始化。然后appmaster与对应的nodemanager通信，要求nodemanager启动container

6.container运行期间，appmaster对container进行监控，container向对应的appmaster进行汇报自己的进度和状态信息

7运行结束后，appmaster向resourcemanager注销自己，并回收container

#### 26.请简述数仓特点

1.面向主题

2.集成性

3.非易失性

4.时变型



#### 27.请简述OLAT和OLTP的区别（数据仓库和数据库的区别）？

数据库：OLTP，联机事务处理

​				主要面向业务，存储业务系统产生的各种数据，大多数操作都是增删改查

​				对数据的时效性，安全性要求较高，且数据相对较少

数据仓库：OLAT，联机分析处理

​					主要面向主题，存储的数据一般都是离线数据，用于分析的数据源，且大多数操作都是查

​					对数据的时效性要求不高，主要关注数据量

​					



#### 28.Hive的三种部署方式，内嵌模式，本地模式，远程模式的区别是什么？

#需不需要手动开启metastore（元数据服务）

#是否可以使用第三方的数据库

#受否可以实现共享



内嵌模式：不需要，不能，不能

本地模式：不需要，能，能（metastore服务不能，mysql可以共享）

远程模式：需要，能，能（metastore，mysql）



#### 29.Hive的内部表和外部表的区别？

1.创建格式不同；直接创建默认是内部表，写上external是外部表

2.删除内部表时，元数据和源文件都会被删除，外部表删除时只会删除元数据，不会删除源文件

3.内部表可以结合事务一起使用，外部表不可以



#### 30.Hive的分区表和分桶表的区别？

分区组字段必须是表中没有的字段，分桶字段必须是表中有的字段

分区相当于分文件夹，为了减少扫描次数

分桶相当于分文件，为了减少join次数

它们都是为了提高查询效率



#### 31.cluster by, distribute by, sort by, order by的区别是什么?

order by:会对数据全局排列，只启动一个reduce进行处理

sort by：局部排序，对分桶后，对每个桶内的数据按照字段排序

cluster by：如果分桶字段和分桶后桶内排序字段是同一个，可以使用

distribute by:按照分桶字段把表内数据分成N份

#### 32.请简述四舍五入原理是什么?

+0.5，求地板数

 floor() 地板数, 比这个数字的小所有整数中, 最大的那个整数.



#### 33.行存储 和 列存储的区别是什么? 

行存储：对select * from这种全查询效率较高

​	缺点：数据之间结构稀疏，磁盘空间利用率较低

列存储：对select 列名 from这种列裁剪方式效率较高

​				数据之间结构紧凑，对磁盘空间利用率也较高



#### 34.Hive调优

##### 1.选择合理的压缩协议和存储格式

​	合理的的压缩方式（zlib、snappy）可以减少IO和磁盘占用率

​	合理的存储格式可以提高查询效率，因为数仓需要根据需求查询不同的维度，所以使用列存储效率较高

##### 2.join优化,防止数据倾斜

###### 1.开启mapjoin：

1.修改hive-site.xml文件

2.将参数hive.auto.convert.join设置为true。

3.设置hive.mapjoin.smalltable.filesize的值，这是用于指定mapjoin操作中的小标的大小阈值，以字节为单位



​	A.小表join小表时，设置阈值：set.mapjoin.smalltable.filesize=25000000;

​		可以在内存中对两张表的数据提前做合并，降低reduce阶段jion，避免数据倾斜。



​	B.小表join大表时，先对大表进行空值过滤，



##### 3.使用分桶和分区，可以提高查询效率

分区=分文件夹,分桶=分文件



##### 4.对小文件进行合并，减少Map数

我们使用的CM平台，可以在CM上直接设置



hive.merge.mapfiles：改为true开启map端小文件合并

hive.merge.mapredfiles：改为true开启reduce端小文件合并

hive.merge.size.per.task：设置输出文件大小，默认为256M

hive.merge.smallfiles.avgsize：当平均大小小于此设置值是，启动一个独立的mapreduce任务进行文件合并，默认值为16M。



##### 5.调整MR的并行度

在job.xml文件中找到mapreduce.job.reduces参数来调整并行度

1个block块=1个maptask任务

1个分区=1个reduce task任务



##### 6.fetch抓取

就是HiveSQL能不转MR就不转MR，能直接执行就直接执行

在hive-default.xml.template文件中set.hive.fetch.task.conversion=more;

设置完成后，全局查询、字段查询、limit等都不走MR



7.

#### 35.请简述你对数据倾斜的理解，怎么解决? 

数据倾斜就是数据key分布不均一，造成一部分数据多，一部分数据少

##### 1.针对join产生的数据倾斜

开启mapjoin：set hive.auto.convert.join=true;

1.小表join小表时可以使用mapjoin，设置小表的阈值：set hive.mapjoin.smalltable.filesize=

​	将小表加载到内存中去，在map端join避免再reduce端，避免数据倾斜

2.小表join大表时，mapjoin开启的同时，可以（使用is not null）对大表先进行空值过滤

3.如果是大表join大表，使用SMBjoin（sort merge bucket join），将两个表按照连接键进行排序，排序后将两表进行合并，期间，连接	键相同的值将会合并，最后将合并后的结果进行桶化（按连接键进行分桶）操作，可以提高查询效率。但是会增加额外的计算和存储开	销

​	SMBjoin可实现map端完成join操作，有效减少了或避免了shuffle的数据量（或减少了reduce端的数据量），避免了数据倾斜。



##### 2.group by数据倾斜

1.设置开启负载均衡set.hive.groupby.skewindata=true;

​	会开启两个MR来处理数据



2.开启在map端预聚合(spark的reduceByKey)，减少传输给reduce的数据量
	默认开启：hive.map.aggr=true；



##### 3.增加reduce端数量





#### 35.1为什么map端join可以避免数据倾斜？

因为map的数量是由数据量来决定的，不会发生数据倾斜



#### 35.2请举一个你遇见的数据倾斜的例子



#### 36.Hive的索引

##### 0.Hive自带索引

hive3.0后废弃

##### 1.行组索引（row group index）

作用：提升数值类型字段为条件进行><=查询性能

条件：表的存储格式必须使用ORC

##### 2.布隆过滤索引

作用：针对=值操作条件，对><操作不生效，对字段类型没有要求

条件：1.必须使用ORC存储格式

​			2.建表时需设置哪些列构建布隆索引



#### 37.窗口函数

窗口函数相当于给表新增加一列，至于增加什么内容取决于窗口函数结合什么函数一起使用

##### 排序函数：

row_number()：相同值不并列排名，一直连续排列

rank（）：相同值并列排名，但是会跳过下一排名

dense_rank()：相同值会并列排名，不会跳过下一排名，后面连续排列。



##### 其他函数：

1.lag()：窗口内统计往上N行

2.lead（）：窗口内统计往下N行

3.first_value：取分组排序后，截至到当前行的第一个值

4.last_value：去分组排序后，截至到当前行的最后一个值



#### 38.内存溢出

数据量大，超出Yarn的集群的内存负载即为内存溢出

##### 解决方法：

1.关闭mapjoin

2.分批导入

3.升级服务器，增加yarn内存



#### 39.请说一下sqoop的相关参数

connect：连接地址

table：表名

username：账号

password：密码

hcatalog-database：要导入的库名

hcatalog-table：要导入的表名

hive-table：要导入的表名

direct：直接导入

hive-overwrite：覆盖写入

create-hive-table：创建在hive中创建一个一模一样的表

m 1 参数代表的含义是使用多少个并行，1代表未开启并行

#### 40.SQL优化

1.使用列裁剪，只读取必要的列，减少数据传输量

2.使用union all代替union，union会去重，是用union all效率较高

3.合理使用disrinct

4.oeder by后使用limit，可以缩短加载数据时间

5.join时大表放左边

6.替换非ORC格式的Hive表

7.join是优先使用inner join，如果使用left join，左表结果尽量要小





#### 41.presto的集群部署、异构数据问题和内存优化

Presto并不支持insert overwriteI覆盖写入语法



#### 42.怎么进行清洗转换？



#### 43.union all和full join的区别？

union all就是将要联合查询的表直接拼接起来（亲提示两张表的字段，顺序，类型要保持一致）

full join的查询结果是左表的全集+右表的全集+交集，相当于左外连接+右外连接

#### 44.Sqoop导入数据后，如何验真？

总量校验：

条件校验：

样本脚本：



#### 45.Hive的架构？

Clinent：客户端

Driver：驱动：1.解析器：将SQL语句转换成抽象语法树（AST），并对SQL进行分析，检测SQL语句是否有误

​				           2.编译器：将AST编译生成逻辑执行计划

​                           3.优化器：对逻辑执行计划进行优化提升执行效率

​						   4.执行器:负责具体的任务执行（转成MR）

metastore：元数据存储，负责管理和存储元数据

计算引擎：MR 



#### 46.请简述一下ORC和Parquet这两种存储格式的区别？

ORC和parquet都是列存储格式，都具有很高的压缩比，能够减少存储空间占用，

它们的不同：

1.ORC读取数据时可以从任意一行读取，可以提高查询速度，parquet是以二进制方式存储，不可以直接读取和修改

2.ORC和Parquet都支持复杂的数据结构，但parquet不支持嵌套数据格式

3.对于数仓来说还是选择ORC更为合适



#### 47.sqoop原生API和Hcatalog的区别？

1.Sqoop原生API支持的数据格式较少（这也是Hcatalog用的多的主要原因），Hcatalog支持的数据个数较多，包括RCFile、ORCfile、    CSV、json等格式

2.Sqoop原生API允许数据覆盖，Hcatalog不允许数据覆盖，每次都是追加

3.Sqoop原生API是顺序匹配字段，而Hcatalog是通过字段名字进行匹配





#### 48.缓慢渐变维类型

SCD1：直接覆盖数据

SCD2：在源数据发生变化时，给记录新建一个版本的记录，从而维护历史记录

SCD3：只希望维护更少的数据



#### 49.什么时候会建立索引？

索引是提升查询效率

1.表的主键和外键

2.表的数据量超过300列

3.在需要和其他表进行连接的连接字段上建立索引

4.经常使用where条件筛选的字段

5.索引尽量建立在小字段上，对于大文本字段甚至超长字段不要建立索引



#### 50.namenode宕机怎么处理？

通过ZK的watch监听机制+临时节点实现HDFS的主备切换

1.当集群开启时所有namenode都会请抢占式的到ZK集群下创建一个临时节点，

2.谁创建成功谁就是Active，其他的为StandBy

3.StandBy状态下的namenode会实时监听Active的namenode的状态

4.当Active状态的namenode宕机了，StandBy状态的namenode就会立刻切换为Active状态并开始工作，

5.为了防止脑裂，Standby状态namenode会通过SSH远程登陆到Active的namenode的集群上使用kill-9杀死namenode。



#### 51.shuffle的含义？

shuffle就是洗牌，将数据打乱重洗再按规律重组的过程



#### 52.HiveSQL的更新和删除问题

Hive默认不支持事务，所以不支持update、delete等操作，如需使用需要开启事务（配置文件名为hive-site-xml）之后就支持update和delete操作。

注意：开启事务之后，之前的表不能操作，需要重新建表来操作。



#### 53.Presto不支持什么操作？

不支持指定数据库（参数设置的）以外的数据源，不支持建表和插入等非查询操作



#### 54.Presto不支持insert overwrite操作怎么办？

Presto不支持insert oversrite操作，无法直接覆盖，可以使用临时表，将结果导入临时表，再使用delete from或truncate table（推荐）将旧表数据删除，删除后，通过insert into操作再将临时表数据导入即可。





#### 55.Hive报错，怎么精准定位错误原因？

##### 方法一：

1.查看Hive的日志文件（一般位于$HIVE_JOME/logs目录下）

2.再日志中找到出错的任务的JOB_ID（例：job_149791335477_0007）

3.通过8088端(UI界面点击左边的‘运行’或‘历史’按钮)在Yarn中找到对应的JOB_ID，进入作业详情界面，点击日志连接，就可以查看错误日	志了

##### 方法二：

1.hadoop支持日志聚合功能，可以将任务的日志收集到HDFS的一个中心位置

2.这需要在yarn-site.xml中配置yarn.log-aggregation-enable为true

3.然后就可以使用Yarn的日志工具yarn logs-applicationld来查看整个应用的日志了





#### 56.同比和环比什么意思

同比：当前月份和去年这个月份的对比

环比：当前月份和上个月的对比



#### 57.面试题: 数仓 和 数据集市的区别?

-- 答案: 数仓是整个公司所有的业务, 数据集市是某个业务线 或者 某个工作组所需数据.



#### 58.请简述你对范式建模和维度建模的理解？



#### 59.小文件合并

##### 小文件产生的原因：

1.Hive的分区分桶机制，如果分区范围设置的过小（如：小时分钟秒）或者分桶的数量过多，则会产生小文件；

2.手动调整reduce数量参数后，reduce越多，小文件也越多（reduce的个数和输出文件是对应的）

3.数据源本身就包含大龄的小文件，比如图片库中的图片都很小，而且无法合并

##### 小文件的影响（危害）

1.元数据影响：namenode将文件的源数据存储在内存中，小文件过多会占用很大内存甚至撑爆内存

2.MR任务影响：在MR中，对每个文件都会启动一个maptask，如果小文件太多会影响性能

3.在HDFS中小文件越多，查询时间越长





##### 预防小文件产生：

我们使用的CM平台，可以在CM上直接设置



hive.merge.mapfiles：改为true开启map端小文件合并

hive.merge.mapredfiles：改为true开启reduce端小文件合并

hive.merge.size.per.task：设置输出文件大小，默认为256M

hive.merge.smallfiles.avgsize：当平均大小小于此设置值是，启动一个独立的mapreduce任务进行文件合并，默认值为16M。



##### 小文件产生后合并：

1.如果是ORC格式的数据，使用以下命令进行合并

```mysql
alter table ${tb_name} partition(...) concatenate;
```

该命令可以连续运行多次，将分区文件个数有效减少。

2.如果不是ORC格式，可以使用以下命令

```mysql
insert overwrite table ${tb_name} partition(...) select * from ${tb_name}  distribute by ${colume_name} (rand()*N);
```

该命令可以将小文件个数合并到指定数量(N)以内

# 项目

##### 0.公司相关信息

#### 个人介绍参考

面试官您好,我叫xxx,来自XXX。下面为你介绍我参与的一个项目，项目名称为亿品新零售项目。该项目是由一家连锁超市公司发起的，发现现在有的传统关系型数据库已满足不了改公司的需求，由此发展而来的数仓开发项目。整个项目的架构分为三大层，ODS层，DW层和RPT层。其中DW层又细分为DWD，DWB，DWS层和DM层。ODS层的数据来源业务数据库mysql，通过编写sqoop脚本来蒋数据全部导入到ods中，并增加了一个按抽取日期的分区字段。对于DWD层的建模，在这里就要分析好哪些事实表和维度表和对一些无用数据进行清洗，并要对某些表进行拉链表处理如（订单表，商圈表和店铺表），方便后面清洗掉过期数据。到了DWB层，，就拿我做的其中一张订宽表来举例，在这里，其中要对订单表，订单支付表等表进行降维操作形成一张订单明细宽表，并对一些过去数据（end
_
time=9999-99-99）的数据清洗掉。
到了DWS层，要开始按日统计指标，并开始按主题来进行划分宽表，在这层，我负责一个销售主题的宽表，按照订单销售额，平台销售额等指标，和区域，城市商圈等维度来进行统计分析。到DW层，要按年，月，周来统计分析数据，可以根据刚刚统计的DWS层的宽表以及DWD层的日期表来进行统计分析。DM层会在DWS的基础上，针对总/年/季度/月/周进行再聚合形成数据集市。
最后到RTP层的主角就不是我们了，前端的人要做报表展示，他给一个需求，我们按照需求从数仓中拿数据给他们就行。



##### 1.自我介绍

面试官您好,我叫XXX,毕业于xxxxxx，有2年开发经验，之前在上海智凝网络科技有限公司，任职期间，参与开发了智凝云市数据分析平台一期离线数仓、二期用户画像项目。在之前项目中，主要使用到以spark技术栈和hadoop生态圈为主的大数据技术。

##### 2.为什么做这个项目

数仓阶段：

一开始我们的业务数据存在mysql数据库里,随着公司业务量的增长，且数据积攒了4、5年的数据,mysql数据库已无法解决海量数据存储问题和为公司提供决策数据支持，所以我们选择搭建了数仓平台。

用户画像阶段：

后来因为市场竞争的激烈，又受到疫情的冲击，平台的收入能力下滑，公司亏损。为实现用户个性化推荐，召回流失用户，最后实现扭亏为盈，所以公司基于智凝云市数仓平台构架用户画像系统，两个项目合成为智凝云市数据分析平台。

##### 3.项目人员配置

开发人员一共10个

产品经理：1个

前端：javaweb+前端=3个

数据挖掘工程师：1个

大数据开发：3个（负责标签计算）

运维：2个



##### 4.项目开发周期

整个用户画像项目从立项到完工大约用了1年零3个月，前端用时3个月，标签总控开发150个左右

需求调研、评审：4周

设计架构：1周

编码、集成：12周

测试：2周

上线部署，试运行，调优（每2周一次）



##### 5.项目数据量

全量数据：历史存储4、5年的数据，整个数据平台数据为5T左右，冗余存储量为10T

日活用户：50w人



每日新增用户：1w人



每人平均20条左右，每日大概1000W条左右

日增：1000W条记录，每条记录平均1.5K左右，日增15G左右

月增：15G * 30天=450G  （）              450G * 3副本=1350G=1.5T左右

年增：1.5T * 12个月 =18T

服务器：阿里云 32核，内存128g     6台服务器，每台服务器





### 数仓阶段：

##### 趣兜风项目：

明细数据层：

事实表：会员订单表、酒店订单表、酒店退单表、套餐订单表、收藏表

维度表：日期表、城市表、景点表、出行方式表

会员主题：

1.指标：销售收入总额会员总额，会员充值总额、各景点游客量、景点好评量、景点差评量、酒店订单额、自驾路线规划量

2.维度：城市、景点、日期、出行方式（房车、摩旅）、

组合维度：日期+城市、日期+城市+景点、日期+城市+景点+出行方式、

##### 为什么做这个项目

一开始我们的业务数据存在mysql数据库里,随着公司业务量的增长，且数据积攒了4、5年的数据,mysql数据库已无法解决海量数据存储问题和为公司提供决策数据支持，所以我们选择搭建了数仓平台。

##### 项目实现流程

下面我给您讲一下我们的新零售的项目架构，项目使用Cloudera manager平台监控部署架构，我们用sqoop把数据从mysql导入到hdfs中，使用hive映射到ods层，在使用oozie进行T+1定时抽取新增数据，基于hive构建数据中心平台，形成各个业务宽表数据，再用presto统计分析形成各个业务宽表数据，在根据需求形成数据集市，将结果使用Sqoop导出到mysql，最后使用finebi进行展示



##### 数据来源

首先我们数据来源有两个,一个是静态数据源,主要是存放在mysql中,大概有100多张表,我负责的销售,商品,用户主题共23张表,包括订单表,退款表,评价表,商品分类表,区域字典表等等

另一个是动态数据源,通过js埋点,flume采集nginx日志服务器的数据,包括用户的点击,收藏,评论等数据,这一块主要是由我另一个同事负责



##### 项目分层

整个项目的数仓使用**维度建模**分为6层:



1.ODS层：源数据层,不对数据进行任何处理,直接使用sqoop从mysql中导入数仓

2.DDL层：明细数据层，划分事实表和维度表,并对数据进行清洗,过滤无效字段,转换时间格式,保证数据的质量

​					事实表：订单表：fact_shop_order

​								    退单表：fact_refund_order

​									订单支付表：fact_order_pay

​									好评表、差评表、

​									

​					维度表：日期表：dim_date

​									商品表：dim_goods

​									店铺表：dim_store

###### 	DDL层如何实现？

​		从ODS层导入数据到DDL层时第一次使用全量导入，后续每天增量导入，导入时我们使用动态分区，按照starttime分区，然后使用		拉链表存储数据历史状态。

​		第一次全量导入给导入的数据添加上starttime和endtime

​		增量：旧的拉链表 left join 增量数据，他们的结果在union all 增量的数据，把结果写入到临时表，最后覆盖写入到拉链表





3.GDL层：中间数据层, 降维, 形成宽表, 即: 把我们要用的字段从多张表抽取出来, 放到一张表中.

​	

​	三张宽表：订单明细宽表：order_detail           难点：表多

​						店铺明细宽表：shop_detail           难点：自关联较多

​						商品明细宽表：goods_detail         难点：join多容易错乱

###### 	GDL层如何实现？

​		

4.TDL层：服务数据层,基于前边各层的数据, 按照主题进行划分, 获取各主题的 日统计宽表

​	我主要负责销售主题

​	三个主题：销售主题：指标：订单总量、销售收入，各平台收入（安卓app、iosapp、wab商城）、参评订单量、差评单量、退款单量

​										   维度：日期、城市、商圈、店铺、商品大类、中类、小类等

​										   使用grouping sets组合维度

​											组合的维度有：日期、日期+城市、日期+城市+商圈、日期+城市+商圈+店铺、日期+品牌、日期+大类等

​			           店铺主题：      指标：下单次数、下单件数、下单金额、被支付次数、被支付件数、被支付金额、被收藏次数、好评数

​		（由其他同事负责）	 维度：日期、商品

​					   用户主题：     指标：首次登录日期、末次登录日期、登录天数、

​		（由其他同事负责）    维度：日期、用户



5.DML层：数据集市层,主要是基于 TDL层的数据, 进行上卷细化统计操作，统计出年, 月, 周, 日的统计
					实际开发中, DML层根据某些部门的需求实现.

6.APP层：数据应用层,裁剪拼接,得到结果表,方便进行报表展示









##### 6.星型模型的优势？（带上星座模型）

​	星型模型是以事实表为中心多个维度表连接在事实表上，维度之间无关联，适用于项目前期

​	总的来说，星型模型结构简单易于实现，查询效率较高，可以快速定位到需要的数据，而且灵活性高，能够适应复杂多变的分析需求

​	

​	随着业务的发展，需求逐渐增多，到后期的时候大多数维度建模会使用星座模型，而星座模型基于多种事实表，多种维度表，维度表之间无关联，但可以共享维度信息，也就是	事实表不止一个，而一个维度表也可能会被多个事实表用到

##### 7.为什么不用雪花模型？

​	雪花模型是星型模型的扩展，雪花模型是1张事实表，多张维度表，在维度表之间相互关联，适用于羡慕的中后期，但是层层join效率低，维护成本高开发难度大，一般不用







##### 8.项目中遇到的三个问题？

​	1.存储问题：起初我们为了节省磁盘空间，所有成为层都采用zlib压缩格式，但是zlib压缩率高，压缩性能一般，后续我们，只用ODS层		使用zlib压缩格式，其他层使用snappy压缩格式，因为snappy压缩速度高，压缩率也均衡。

​	2.Mysql抽取数据全量到ODS层时，由于数据量过大，导致数据采集失败，后面写了一个shell脚本分批循环导入

​	3.查询：多级分类采用子查询提高代码效率



##### 9.数仓从0到1

​	1.了解需求，包括原始数据结构

​	2.根据需求提取指标（事实表）和维度（维度表）

​	3.设计分层

​		ODS层：源数据层。使用orc+zilb，保存原始数据

​		DDL层：明细数据层。（后面的层都）使用orc+snappy,对数据清洗转换，使用拉链表维护和存储历史数据

​		GDL层：中间数据层。明细宽表，降维（把我们要用到的字段从多张表中抽取出来，放到一张表中）

​		TDL层：服务数据层。日统计宽表，按天进行轻度聚合

​		DML层：数据集市层。对总累积、年、季度、月、周、天进行统计，或根据某些部门的要求进行统计

​		APP层：数据应用层。

​	4.建模

​		ODS：数据和原始数据保持一致，增加抽取日期作为分区

​		DDL：增加生效日期和结束日期，使用拉链表存储和维护历史数据

​		GDL：降维（将我们需要用的字段抽取出来放到一张表中）关联形成明细宽表

​		TDL：按照主题进行日统计，字段包含指标和维度、group_type(组别)

​		DML：按照主题进行统计，字段包含指标维度group_type、年、季度、月、周、日、time_type

​		APP：个性化需求，按照需求走

5.实现抽取计算











# 新零售项目

#### 0.项目

lambda架构：流处理和批处理逻辑两套代码，画像的标签计算代码是批处理代码【spark结合es、hive】，日志实
时统计是流处理代码【spark结合kafka、mysql】
kappa架构：流处理和批处理一套代码，基于flinksql可以实现实时和离线数据分析，统一处理实时离线数据源

1.ods使用zlib协议，压缩率高，压缩性能一般，ods文件较大所以使用zlib

2磁盘足使用orc+snappy（snappy高压缩速度，合理的压缩率）

#### 1.实现拉链表操作                  面试问: 为什么要有拉链表?     答: 存储和维护 历史数据的.  (缓慢渐变维SCD2)

##### 	A.首次导入



```mysql
	1.使用全量导入，采用动态分区insert方法导入，按生效时间分区
	INSERT overwrite TABLE yp_dwd.fact_shop_order PARTITION (start_date)
	SELECT 
	。。。
	FROM yp_ods.t_shop_order;
	
	
	2.平台有android、ios、小程序等所以使用case when语句转换
	  case order_from 
      when 1
      then 'android'
      when 2
      then 'ios'
      when 3
      then 'miniapp'
      when 4
      then 'pcweb'
      else 'other'
      end
      as order_from,
```
##### 	B.增量导入

​		1.创建临时表（临时表的结构和拉链表一样）用于记录:  拉链表 和 增量采集信息表 更新后的数据

​			用于存储 拉链表 和 增量采集信息表

​		2.把 拉链表的数据 和 增量采集信息表数据, 添加到临时表中, 如果是修改数据, endTime记录为 9999-12-31

​			（将原有拉链表left join增量表找出有修改的数据，也就是endtime改变了的，在使用union all连接上述表和增量信息表，然后覆盖写入到临时表，最后覆盖写入到拉链表）

​			拉链公式=（旧的拉链表 left join 增量表）union all 增量表 



其中最重要的endtime判断语句

​			![image-20230906220536263](C:\Users\15263\AppData\Roaming\Typora\typora-user-images\image-20230906220536263.png)

​		3.把临时表中的数据(即: 最新的拉链数据), 全量覆盖到拉链表中



#### 2.数仓各层的作用和实现方法

​	1.ODS层：源数据层，使用Orc+zlib，

​	2.DDL层：明细数据层，使用Orc+Snappy，主要是· 拉链表操作，这一层主要是清洗转换数据，区分事实表和维度表

​	3.GDL层：中间数据层，降维,关联形成宽表, 即: 把我们要用的字段从多张表抽取出来, 放到一张表中.    负责订单宽表，以订单主表为核		心

​	4.TDL层：服务数据层，基于前边各层的数据, 按照主题进行划分, 获取各主题的 日统计宽表，，我负责销售主题

​	5.DML层：数据集市层，主要是基于 DWS层的数据, 上卷出 年, 月, 周, 日的统计

​	6.APP层：数据应用层，

#### 3.grouping sets的用法

​	grouping sets的作用是根据不同维度进行聚合

​	grouping sets在Hive和Presto中作用一模一样，但是写法不同，grouping sets是写在group by之后的

​	在hive中使用gronging sets需要在group by后写上相同字段

​	在Presto中不用在group by后面写字段，Presto会根据后面的字段自动填充

#### 4.说一下cube和rollup的用法

​	cube的作用可以实现任意维度的组合，维度组合数量是2的n次方

​	比如传入2个维度 1、2，则组合的维度就是（1，2），1，2，空  四个组合

​	cube写在group by的后面

```mysql
select month,day,count(cookieid)
from test.t_cookie
group by
cube (month, day);
```

​	

​	rollup的作用是从右向左递减实现多级统计

​	也就是说传入abc三个维度，他的组合是（abc），（ab），（a），（空）



#### 5.说一下grouping的用法

​	grouping的作用是判断当前结果属于哪个维度，0代表有，1代表没有

```mysql

select month,
       day,
       count(cookieid),
       grouping(month)      as m,
       grouping(day)        as d,
       grouping(month, day) as m_d
from test.t_cookie
group by
   grouping sets (month, day, (month, day));
```



#### 6.我们目前的表数据中, 有大量的数据是完全重复的，该怎么去重

​	使用distinct和group by会直接修改表结构所以不能使用

​	可以使用窗口函数row_number+CTE表达式去重

​	

```mysql
###根据谁（哪个字段）去重，就根据谁（哪个字段）分组
###例：根据oid去重
-- 1.1 需求1: 只以订单oid去重,  思路: row_number() + CRT表达式.
with t1 as (
    select
       *,
       row_number() over(partition by oid) id_rn
    from test.t_order_detail_dup
)
select * from t1 where id_rn = 1;

-- 1.2 需求2: 以订单oid+品牌brand_id去重
with t1 as (
    select
           *,
           row_number() over(partition by oid, brand_id) rn
    from test.t_order_detail_dup
)
select * from t1 where rn = 1;

-- 1.3 需求3: 再比如以订单oid+品牌brand_id+商品goods_id去重
with t1 as (
    select
           *,
           row_number() over(partition by oid, brand_id, goods_id) rn
    from test.t_order_detail_dup
)
select * from t1 where rn = 1;






！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！
1.4 需求4: 把上述所有的去重条件, 合并到一起(写)
with t1 as (
    select
           *,
           row_number() over(partition by oid) rn1,                     -- 按照 oid 去重
           row_number() over(partition by oid, brand_id) rn2,           -- 按照 oid, brand_id 去重
           row_number() over(partition by oid, brand_id, goods_id) rn3  -- 按照 oid, brand_id, goods_id 去重
    from test.t_order_detail_dup
)
select * from t1 where rn1 = 1;

```

​	





#### 7.面试题: 数仓 和 数据集市的区别?

-- 答案: 数仓是整个公司所有的业务, 数据集市是某个业务线 或者 某个工作组所需数据.

#### 8.请简述一下维度建模和三范式建模的？
